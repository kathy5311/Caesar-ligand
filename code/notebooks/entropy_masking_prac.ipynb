{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0.]]])\n",
      "tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n"
     ]
    }
   ],
   "source": [
    "# 예제 데이터 생성 (len(Gs), nfull, max(njs))\n",
    "len_Gs = 5\n",
    "nfull = 10\n",
    "max_njs = 7\n",
    "target_tensor = torch.randn(len_Gs, nfull, 1)  # [len(Gs), nfull, 1] 텐서\n",
    "\n",
    "# mask 생성 예제 (len(Gs), nfull, max(njs))\n",
    "mask = torch.zeros((len_Gs, nfull, max_njs))\n",
    "mask[:, :5, :5] = 1  # 예시로, 첫 5개의 노드를 활성화\n",
    "print(mask)\n",
    "# mask를 [len(Gs), nfull, 1] 형태로 변환\n",
    "reduced_mask = mask[:, :, 0].unsqueeze(-1)\n",
    "print(reduced_mask)\n",
    "# 마스킹 적용\n",
    "masked_tensor = target_tensor * reduced_mask\n",
    "\n",
    "#print(masked_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# 활성화된 노드의 개수 및 값 출력\\nfor i in range(len_Gs):\\n    print(f\"Graph {i+1}: Active nodes = {active_nodes_count[i].item()}\")\\n    print(f\"Target values: {active_target_values[:active_nodes_count[i].item()].tolist()}\")\\n    active_target_values = active_target_values[active_nodes_count[i].item():]  # 다음 그래프의 값으로 이동'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제 데이터 생성 (len(Gs), nfull, max(njs))\n",
    "len_Gs = 5\n",
    "nfull = 10\n",
    "max_njs = 7\n",
    "target_tensor = torch.randn(len_Gs, nfull, 1)  # [len(Gs), nfull, 1] 텐서\n",
    "p1 = torch.ones(1)\n",
    "#print(p1.shape)\n",
    "# mask 생성 예제 (len(Gs), nfull, max(njs))\n",
    "mask = torch.zeros((len_Gs, nfull, max_njs))\n",
    "mask[:, :5, :5] = 1  # 예시로, 첫 5개의 노드를 활성화\n",
    "#print(mask.shape)\n",
    "#print(mask[0])\n",
    "b=mask.shape[0]\n",
    "i=mask.shape[1]\n",
    "j=mask.shape[2]\n",
    "reshapeT=mask.view(b,i*j,1)\n",
    "print(reshapeT[0])\n",
    "# mask를 [len(Gs), nfull, 1] 형태로 변환\n",
    "reduced_mask = mask[:, :, 0].unsqueeze(-1)\n",
    "#print(reduced_mask[0])\n",
    "# 활성화된 노드의 개수 계산\n",
    "active_nodes_count = reduced_mask.sum(dim=1).int()  # [len(Gs), 1] 텐서\n",
    "\n",
    "# 활성화된 노드의 target_tensor 값만 선택\n",
    "active_target_values = target_tensor[reduced_mask.bool()].view(-1, 1)\n",
    "active_nodes_per_graph = (mask.sum(dim=2) > 0).sum(dim=1)\n",
    "#print(active_nodes_per_graph)\n",
    "'''\n",
    "# 활성화된 노드의 개수 및 값 출력\n",
    "for i in range(len_Gs):\n",
    "    print(f\"Graph {i+1}: Active nodes = {active_nodes_count[i].item()}\")\n",
    "    print(f\"Target values: {active_target_values[:active_nodes_count[i].item()].tolist()}\")\n",
    "    active_target_values = active_target_values[active_nodes_count[i].item():]  # 다음 그래프의 값으로 이동'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 활성화된 노드 개수가 몇 개인지 파악해서 이걸로 노말라이즈하면 되지 않을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n",
      "tensor([[[0],\n",
      "         [1],\n",
      "         [0]],\n",
      "\n",
      "        [[1],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[1],\n",
      "         [1],\n",
      "         [1]]])\n",
      "tensor([[5, 6],\n",
      "        [4, 0],\n",
      "        [7, 3]])\n",
      "tensor([[[0, 0],\n",
      "         [4, 0],\n",
      "         [0, 0]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [0, 0],\n",
      "         [0, 0]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [4, 0],\n",
      "         [7, 3]]])\n"
     ]
    }
   ],
   "source": [
    "# Define the tensors\n",
    "tensor1 = torch.randint(0,2,(3, 3, 1))  # Shape [5, 70, 1]\n",
    "tensor2 = torch.randint(0,10,(3, 2))  # Shape [5, 70, 4]\n",
    "\n",
    "# Perform element-wise multiplication with broadcasting\n",
    "result = tensor1 * tensor2  # Resulting shape will be [5, 70, 4]\n",
    "\n",
    "print(tensor1.sum())\n",
    "# Verify the shape of the result#\n",
    "print(tensor1)\n",
    "print(tensor2)\n",
    "print(result)  # Output: torch.Size([5, 70, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14, 10,  5,  4],\n",
      "        [ 6, 17, 21, 13],\n",
      "        [10,  8, 15, 16],\n",
      "        [23, 21, 16, 15],\n",
      "        [ 4,  6,  8,  3]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(result,dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[3, 3, 1]' is invalid for input of size 45",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tensor1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m tem\u001b[38;5;241m=\u001b[39m\u001b[43mtensor1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(tem)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[3, 3, 1]' is invalid for input of size 45"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.randint(0,2,(3, 3, 5))\n",
    "tem=tensor1.view(3,3,1)\n",
    "print(tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1],\n",
      "         [0],\n",
      "         [0],\n",
      "         [1],\n",
      "         [1]],\n",
      "\n",
      "        [[1],\n",
      "         [1],\n",
      "         [1],\n",
      "         [1],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [1],\n",
      "         [1],\n",
      "         [1]],\n",
      "\n",
      "        [[1],\n",
      "         [1],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [1],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]]])\n",
      "tensor(13)\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.randint(0,2,(5, 5, 1))\n",
    "print(tensor1)\n",
    "print(tensor1.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(64.)\n",
      "tensor(64)\n",
      "tensor([[[2.],\n",
      "         [0.],\n",
      "         [3.],\n",
      "         [2.],\n",
      "         [3.]],\n",
      "\n",
      "        [[3.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [3.],\n",
      "         [3.]],\n",
      "\n",
      "        [[3.],\n",
      "         [3.],\n",
      "         [4.],\n",
      "         [2.],\n",
      "         [2.]],\n",
      "\n",
      "        [[3.],\n",
      "         [3.],\n",
      "         [0.],\n",
      "         [3.],\n",
      "         [2.]],\n",
      "\n",
      "        [[4.],\n",
      "         [4.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [4.]]])\n",
      "tensor([[[0, 1, 0, 0, 1],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [1, 0, 1, 0, 1],\n",
      "         [1, 0, 0, 0, 1],\n",
      "         [0, 1, 1, 1, 0]],\n",
      "\n",
      "        [[1, 1, 0, 1, 0],\n",
      "         [0, 0, 1, 0, 1],\n",
      "         [0, 0, 1, 0, 1],\n",
      "         [1, 1, 0, 0, 1],\n",
      "         [1, 1, 0, 1, 0]],\n",
      "\n",
      "        [[1, 0, 1, 1, 0],\n",
      "         [0, 1, 0, 1, 1],\n",
      "         [1, 1, 1, 0, 1],\n",
      "         [1, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 1]],\n",
      "\n",
      "        [[1, 1, 0, 0, 1],\n",
      "         [0, 1, 1, 0, 1],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [1, 0, 0, 1, 1],\n",
      "         [0, 0, 0, 1, 1]],\n",
      "\n",
      "        [[0, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 0],\n",
      "         [0, 0, 1, 1, 0],\n",
      "         [0, 1, 0, 0, 1],\n",
      "         [1, 1, 0, 1, 1]]])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.randint(0,2,(5, 5, 5))\n",
    "per_entropy_weight = torch.ones(1)\n",
    "weight = torch.einsum('bij,k->bik', tensor1, per_entropy_weight)\n",
    "print(weight.sum())\n",
    "print(tensor1.sum())\n",
    "\n",
    "print(weight)\n",
    "print(tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
